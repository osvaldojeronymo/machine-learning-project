---
title: "Projeto de Machine Learning I"
author: "Bruno Lenz, Danilo Santos, Diogo de Araujo, Jonathan e Osvaldo Jeronymo Neto"
date: today
date-format: long
lang: pt-BR
number-sections: true

# Rotular tabelas como "Quadro" e personalizar Ap√™ndice
crossref:
  tbl-title: "Quadro"      # muda o r√≥tulo na legenda
  tbl-prefix: "Quadro"     # muda o texto nos @tbl-...
  title-delim: " ‚Äî "
  appendix-title: "Ap√™ndice"
  appendix-delim: " ‚Äî "

format:
  html:
    toc: true
    theme: cosmo
    tbl-cap-location: top

bibliography: referencias.bib
csl: abnt.csl
---
# Introdu√ß√£o

Este projeto explora a aplica√ß√£o de t√©cnicas de ***Machine Learning (ML)*** para a an√°lise de dados banc√°rios multimodais, com o objetivo de desenvolver um modelo preditivo para otimizar campanhas de ***cross-sell*** (venda-cruzada). A an√°lise se baseia no ***Multimodal Banking Dataset (MBD)***, um conjunto de dados em larga escala que reflete intera√ß√µes reais de clientes corporativos. 

A metodologia adotada para alcan√ßar esse objetivo abrange um ciclo completo de desenvolvimento de um modelo de *ML*. O processo inicia com a **defini√ß√£o do problema de neg√≥cio** e avan√ßa para as etapas de **tratamento e transforma√ß√£o dos dados**, que s√£o cruciais dado o car√°ter multimodal do *dataset*. Subsequentemente, define-se a **m√©trica de avalia√ß√£o** mais adequada para o problema de *cross-sell*, seguida pelo desenvolvimento e treinamento de uma solu√ß√£o de *ML* que emprega, no m√≠nimo, tr√™s estimadores distintos. Para maximizar a performance, realiza-se a **otimiza√ß√£o de hiperpar√¢metros** desses algoritmos, visando a melhoria da m√©trica de interesse. O projeto culmina com uma **an√°lise comparativa dos modelos**, resultando na sele√ß√£o do estimador de melhor desempenho.

A relev√¢ncia estrat√©gica deste projeto √© refor√ßada por evid√™ncias que apontam a maior propens√£o de clientes existentes em adquirir novos produtos da mesma institui√ß√£o, uma pr√°tica conhecida como cross-selling (@basten2023). Portanto, o trabalho culmina n√£o apenas na entrega de um modelo preditivo validado, mas tamb√©m em uma an√°lise sobre sua efic√°cia para a resolu√ß√£o do problema de neg√≥cio e um delineamento das etapas essenciais para sua futura implementa√ß√£o em um ambiente de produ√ß√£o.

# Contexto

A primeira etapa do projeto consistiu na sele√ß√£o de um *dataset* apropiado. A comunidade [***Hugging Face***](https://huggingface.co) foi a fonte escolhida, e dentro da diversidade de *dataset* contidos nessa comunidade optou-se pelo  [Multimodal Banking Dataset - MBD](https://huggingface.co/papers/2409.17587).

Conforme descrito por @mollaev2025, o **MBD** √© o primeiro conjunto de dados banc√°rio multimodal, de larga escala e publicamente dispon√≠vel. Esse *dataset* cont√©m sequ√™ncias de dados anonimizados de mais de 2 milh√µes de clientes corporativos de um grande banco. Este dataset inclui **transa√ß√µes financeiras, dados de geolocaliza√ß√£o, di√°logos de suporte t√©cnico e registros de compras de produtos**. O obetivo da sua cria√ß√£o foi preencher a lacuna de dados abertos no setor financeiro, viabilizando o desenvolvimento de t√©cnicas avan√ßadas de aprendizado profundo. Adicionalmente, os autores prop√µem um novo **benchmark multimodal** com tarefas pr√°ticas como a previs√£o de futuras compras, que se alinha diretamente com os objetivos desse projeto.

## Problema de neg√≥cio

O problema de neg√≥cio selecionado √© a **predi√ß√£o de propens√£o √† compra em campanhas de *cross-sell* (venda-cruzada)**. Uma campanha de *cross-sell* √© uma iniciativa de marketing direcionada a clientes existentes, com o intuito de oferecer produtos complementares aos que j√° possuem. Por exemplo, oferecer seguro de vida a um cliente que recentemente contratou um financeiro imobili√°rio. 

O objetivo deste projeto √©, portanto, treinar um modelo com o **MBD** para gerar um *score* de propens√£o para cada cliente. Esse *score* permitir√° priorizar os clientes com maior probabilidade de aceitar uma oferta, otimizando os recursos da campanha e aumentando a sua taxa de convers√£o.

**Delimita√ß√£o do escopo: cross-sell *vs.* up-sell**

Para garantir a clareza do objetivo, √© necess√°ria uma distin√ß√£o: o escopo deste projeto √© estritamente o ***cross-sell***. √â importante n√£o confundi-lo com ***up-sell***, que consiste em incentivar o cliente a adquirir uma vers√£o mais avan√ßada ou mais cara de um mesmo produto que ele j√° possui (ex: migrar de um cart√£o de cr√©dito "Gold" para um "Platinum"). O modelo aqui desenvolvido focar√° exclusivamente na oferta de novos e diferentes produtos.

## Reposit√≥rio

Os artefatos gerados durante o desenvolvimento deste projeto, incluindo notebooks, scripts e relat√≥rios, est√£o organizados da seguinte forma e podem ser encontrados no seguinte reposit√≥rio: <https://github.com/osvaldojeronymo/machine-learning-project>.

```
/notebooks
  01_explore_mbd_mini.ipynb
  02_features_tabular.ipynb
  03_train_compare_tabular.ipynb
  04_ptls_sequence_embeddings.ipynb
/src
  data_loading.py
  features_trx.py / features_geo.py / features_dialog.py
  train_tabular.py (Optuna + GroupKFold)
  train_ptls.py
/reports
  metrics_by_fold.csv
  feature_importance_{model}.csv
  calibration_plots/
```

## Dados

O [**MBD**](https://huggingface.co/datasets/ai-lab/MBD) cont√©m mais de 2 milh√µes de dados de clientes corporativos. Nesse projeto optou-se por trabalhar com [***MBD-mini dataset***](https://huggingface.co/datasets/ai-lab/MBD-mini), que cont√©m um subconjunto reduzido dos dados, essa estrat√©gia facilitar√° os trabalhos de desenvolvimento e teste do modelo proposto. Esse ***MBD-mini dataset*** t√™m dados baseados em 10% de clientes √∫nicos listados no **MBD**. Como apresentado por @mollaev2025 no @tbl-overview, t√™m-se:

: Vis√£o geral de conjuntos de dados de transa√ß√µes existentes {#tbl-overview}

| Conjunto de dados         | N¬∫ de clientes | Tarefas-alvo (*downstream*)                             | N¬∫ de eventos | Balan√ßo de classes       | Modalidades                                 |
|---------------------------|---------------:|---------------------------------------------------------|--------------:|--------------------------|---------------------------------------------|
| DataFusion                |        22 mil  | Classifica√ß√£o bin√°ria; *matching* multimodal            |   146 milh√µes | Desbalanceado            | Transa√ß√µes; Clickstream                     |
| Alphabattle               |     1,5 milh√£o | Classifica√ß√£o bin√°ria                                   |   443 milh√µes | Desbalanceado            | Transa√ß√µes                                  |
| Age                       |        50 mil  | Classifica√ß√£o multiclasse                               |    44 milh√µes | Balanceado               | Transa√ß√µes                                  |
| Rosbank                   |        10 mil  | Classifica√ß√£o bin√°ria                                   |     1 milh√£o  | Desbalanceado            | Transa√ß√µes                                  |
| Credit Card Transaction   |         2 mil  | Classifica√ß√£o bin√°ria; Regress√£o                        |     2 milh√µes | Altamente desbalanceado  | Transa√ß√µes                                  |
| MBD-small (nosso)         |        70 mil  | Classifica√ß√£o bin√°ria multirr√≥tulo; *matching* multimodal |    80 milh√µes | Desbalanceado            | Transa√ß√µes; Geostream (eventos geogr√°ficos); Di√°logos |
| MBD (nosso)               |      2 milh√µes | Classifica√ß√£o bin√°ria multirr√≥tulo; *matching* multimodal |     2 bilh√µes | Altamente desbalanceado  | Transa√ß√µes; Geostream (eventos geogr√°ficos); Di√°logos |

**Fonte:** @mollaev2025. DOI: 10.48550/arXiv.2409.17587. *Tradu√ß√£o nossa.*

## Pr√©-processamento

**feature engineering**

## M√©tricas

**Prim√°ria: AUPRC (PR-AUC). Complementares: ROC-AUC, Precision@k, Recall@k, Brier, calibra√ß√£o.**

## Estimadores

**Tabular: Regress√£o Log√≠stica; LightGBM/XGBoost; CatBoost.**
**Sequencial (opcional): ptls (pytorch-lifestream) + cabe√ßote leve.**

## Otimiza√ß√£o

**Optuna (TPE) com early stopping quando aplic√°vel; sele√ß√£o pelo AUPRC m√©dio nas dobras.**

## Sele√ß√£o

**Comparar AUPRC/ROC-AUC, Top-k, calibra√ß√£o, estabilidade (¬±dp) e custo/lat√™ncia.**

# Metodologia

Esta se√ß√£o descreve o delineamento metodol√≥gico adotado, estruturado como um **pipeline de ci√™ncia de dados** para predi√ß√£o em bases **temporais e multimodais**. Parte-se da defini√ß√£o do **alvo** e do **horizonte** de previs√£o e adota-se o paradigma de **minimiza√ß√£o do risco emp√≠rico**, com controle de **vi√©s‚Äìvari√¢ncia** por meio de **valida√ß√£o em grupos** (n√≠vel cliente) e **bloqueio temporal** (*no-lookahead*). 

A representa√ß√£o dos dados combina princ√≠pios de **aprendizado multivisual** (*multi-view*), com **agrega√ß√µes em janelas** (intensidade, rec√™ncia, valor), **medidas de mobilidade espacial** e **pooling de embeddings**, al√©m de **redu√ß√£o de dimensionalidade** para mitigar sobreajuste. Consideram-se dois trilhos de modelagem ‚Äî **tabular** (regress√£o e *gradient boosting*) e **sequencial** (aprendizado de representa√ß√µes) ‚Äî avaliados por m√©tricas robustas a **desbalanceamento** (**AUPRC**, *Precision*@k) e **calibra√ß√£o**. 

A **otimiza√ß√£o de hiperpar√¢metros** segue abordagem **bayesiana** com **parada antecipada**; **abla√ß√µes** e **fus√£o de modalidades** quantificam contribui√ß√µes e sinergias. O processo √© conduzido com **reprodutibilidade** (vers√µes, sementes, *pin* de dados) e **governan√ßa** (privacidade e uso respons√°vel), visando n√£o apenas desempenho preditivo, mas **viabilidade operacional** para prioriza√ß√£o de campanhas.

## Problema e hip√≥tese

Em ci√™ncia de dados, a formula√ß√£o do problema define o alvo preditivo, o horizonte temporal e as unidades de decis√£o. No nosso caso, trata-se de aprendizado supervisionado para classifica√ß√£o bin√°ria em dados temporais e multimodais, no qual buscamos um estimador 
ùëì
(
ùë•
)
f(x) que minimize o risco emp√≠rico (fun√ß√£o de perda) sob restri√ß√µes de desbalanceamento (baixa preval√™ncia) e depend√™ncia temporal. A hip√≥tese central decorre de aprendizado multivisual (multi-view learning): modalidades heterog√™neas e complementares (transa√ß√µes, geolocaliza√ß√£o e di√°logos) capturam aspectos distintos do comportamento do cliente; portanto, sua fus√£o informacional tende a aumentar o poder discriminativo e a estabilidade do modelo frente a abordagens unimodais.

Amarra√ß√£o ao seu texto: essa teoria sustenta: ‚ÄúTarefa de campanha‚Ä¶ estimar target_1. Hip√≥tese: fus√£o multimodal supera unimodal em AUPRC e Precision@k.‚Äù

Tarefa de campanha (purchase prediction): estimar target_1 (m√™s +1) ‚Äî extens√£o opcional a target_2..4. Hip√≥tese: fus√£o multimodal supera unimodal em AUPRC e Precision@k (@mollaev2025).

## Dados e parti√ß√µes

Usa-se MBD (e MBD-mini para POC). Valida√ß√£o por cliente (GroupKFold por client_id ou fold nativo). Em cada mon, apenas eventos com event_time ‚â§ mon entram nas features (no-lookahead).

## Engenharia de atributos

### Transa√ß√µes (trx)

Janelas 1/3/6 meses: RFM, ticket/mediana/desvio, mix por event_type/subtype, diversidade (entropias src*/dst*), sazonalidade (dia/hora, seno/cosseno).

### Geolocaliza√ß√£o (geo)

Contagem; n¬∫ de geohash_5/6 √∫nicos; entropia espacial; mobilidade (trocas de c√©lula; radius of gyration aproximado); rec√™ncia.

### Di√°logos (dialog)

Pooling temporal dos embeddings (m√©dia, m√°x, m√©dia ponderada por rec√™ncia, √∫ltimo vetor) + PCA (16‚Äì64) para reduzir dimensionalidade.

### Jun√ß√£o e alvo

Chaves (client_id, mon); alvo prim√°rio target_1 (bin√°rio). Imputa√ß√£o de ausentes (0/estat√≠stica).

## Modelagem

Tabular: LR; LightGBM/XGBoost; CatBoost.
Sequencial (opcional): ptls (aprendizado auto-supervisionado, p.ex., CoLES) + MLP/GBM.

## M√©tricas e avalia√ß√£o

AUPRC como alvo; ROC-AUC, Precision@k/Recall@k, Brier e curva de calibra√ß√£o. Reporte m√©dia ¬± dp em 5 dobras.

## Otimiza√ß√£o (HPO) e protocolo

HPO com Optuna (TPE). Espa√ßos:
LR (C, L1/L2, class_weight);
LGBM (num_leaves, max_depth, min_data_in_leaf, feature_fraction, bagging_fraction, lambda_l1/l2, learning_rate, n_estimators);
CatBoost (depth, l2_leaf_reg, learning_rate, iterations, scale_pos_weight);
ptls (hidden_size, n_layers, dropout, lr, seq_len, pooling).
Sele√ß√£o final pelo AUPRC m√©dio; tie-breakers: estabilidade, Top-5%, calibra√ß√£o, custo.

## Abla√ß√£o e fus√£o

Abla√ß√£o por modalidade (trx | geo | dialog | full) e late-fusion (concat/blending).

## Organiza√ß√£o dos dados

O @tbl-mbd-schema apresenta a organiza√ß√£o do MBD (@mollaev2025).

: Organiza√ß√£o dos dados do MBD (resumo) {#tbl-mbd-schema}

Camada/Tabela	Campo (tipo)	Descri√ß√£o
client_split	client_id (str); fold (int)	ID anonimizado e dobra oficial
detail.dialog	client_id; event_time; embedding (float[])	Vetores sem√¢nticos de di√°logos
detail.geo	client_id; event_time; geohash_4/5/6	Eventos espaciais hier√°rquicos
detail.trx	client_id; event_time; amount; tipos‚Ä¶	Transa√ß√µes e c√≥digos de tipo/origem/destino
ptls.*	arrays por campo (por cliente)	Sequ√™ncias para modelagem com ptls
targets	mon; target_1..4; trans_count; diff_trans_date; client_id; fold	R√≥tulos por m√™s e estat√≠sticas de rec√™ncia/volume

Fonte: Adaptado de @mollaev2025. DOI: 10.48550/arXiv.2409.17587. Tradu√ß√£o nossa.

Veja o Ap√™ndice A ‚Äî Dicion√°rio de dados.

::: {.callout-tip}
Boas pr√°ticas anti-vazamento: sempre respeite event_time ‚â§ mon; valide por cliente; normalize pipelines com fit no treino e transform no teste/valida√ß√£o.
:::

**Campanha de cross-sell:** dada a historiza√ß√£o de **transa√ß√µes (trx)**, **atividade geogr√°fica (geo)** e **embeddings de di√°logo (dialog)** at√© um m√™s de refer√™ncia `mon`, **prever a probabilidade de emiss√£o de um produto** no(s) pr√≥ximo(s) m√™s(es). O MBD j√° vem com r√≥tulos mensais `target_1`‚Ä¶`target_4` (emiss√£o no +1, +2, +3, +4) e split por cliente/folds ‚Äî √© exatamente o cen√°rio de ‚Äúcampaigning‚Äù proposto pelos autores. ([Hugging Face][2], [arXiv][3])

> * **Tarefa principal:** classifica√ß√£o bin√°ria para **`target_1`** (emiss√£o no m√™s seguinte).
> * **Extens√£o opcional:** modelo **multi-tarefa** para os 4 horizontes (`target_1..4`) com uma √∫nica base de features.

**Tratamentos**

**Premissas anti-vazamento (essenciais):**

* Para cada snapshot mensal `mon`, **use apenas eventos com `event_time` ‚â§ fim de `mon`**.
* Respeite o split por **cliente** (use `fold`/`client_id`) para valida√ß√£o, evitando overlap. O dataset j√° fornece dobras e at√© vers√£o ‚Äúmini‚Äù para prototipagem. ([Hugging Face][2])

***Transa√ß√µes (`detail.trx` ou `ptls.trx`)***

Agregue janelas **1, 3 e 6 meses** (rolling/expanding) at√© `mon`:

* **RFM**: n√∫mero de transa√ß√µes; dias desde a √∫ltima; soma e mediana de `amount`; ticket m√©dio; % cr√©dito vs d√©bito (se aplic√°vel).
* **Mix de tipos**: contagens/percentuais por `event_type` e `event_subtype`.
* **Diversidade**: entropia de `dst_type*`/`src_type*`; n√∫mero de contrapartes √∫nicas.
* **Volatilidade**: std de `amount`; coef. de varia√ß√£o; sazonalidade por dia da semana/hora (one-hot + sen/cos).

***Geo (`detail.geo` ou `ptls.geo`)***

* **Frequ√™ncia e diversidade**: n¬∫ de `geohash_5/6` √∫nicos; entropia; ‚Äúhome geohash‚Äù (moda) e % de tempo nele.
* **Mobilidade**: ‚Äúradius of gyration‚Äù aproximado (decodifique geohash para lat/lon de c√©lula); n¬∫ de trocas de c√©lula; raz√£o dia/noite; fins de semana vs semana.
* **Rec√™ncia**: tempo desde o √∫ltimo evento geo.

***Di√°logos (`detail.dialog` / embeddings)***

* **Pooling temporal**: m√©dia, m√°x, **recency-weighted mean** e **√∫ltimo embedding**.
* **Intensidade**: n¬∫ de di√°logos no m√™s; dias com di√°logo; tempo desde o √∫ltimo.
* **Redu√ß√£o**: PCA/UMAP dos embeddings agregados para 16‚Äì64 dims (evita overfit).

> Observa√ß√£o: o MBD tamb√©m disponibiliza os dados no **formato ptls (pytorch-lifestream)** para modelagem sequencial em larga escala. ([GitHub][4])

***Jun√ß√£o + alvo***

* **Chave:** (`client_id`, `mon`).
* **Alvos:** `target_1` (principal) e, opcional, `target_2..4`.
* **Controles:** `is_balanced` pode filtrar um subconjunto balanceado para experimentos r√°pidos (ou pesar classes). ([Hugging Face][2])

**M√©tricas**

Como campanhas t√™m **baixa preval√™ncia**, priorize m√©tricas robustas a desbalanceamento:

* **AUPRC (Average Precision/PR-AUC)** ‚Äì m√©trica principal.
* **ROC-AUC** ‚Äì complementar.
* **Top-k Precision / Recall\@k** ‚Äì alinhada a or√ßamento de campanha (ex.: top 5% clientes).
* **Calibra√ß√£o** (Brier/plot) ‚Äì importante para sele√ß√£o por score.

**Estimadores**

***Track 1 ‚Äî Tabular (features agregadas)***

1. **Regress√£o Log√≠stica (baseline forte)**
2. **Gradient Boosting**: **LightGBM** *ou* **XGBoost**
3. **CatBoost** (bom para misto categ√≥rico/num√©rico; lida bem com inteiros de c√≥digos)

***Track 2 ‚Äî Sequencial (opcional, eleva teto de performance)***

4. **`ptls` (pytorch-lifestream)** para aprender embeddings de sequ√™ncia (trx/geo) via auto-supervis√£o (p.ex., **CoLES**), seguidos de um **cabe√ßote MLP** para previs√£o. Esse √© o caminho alinhado ao benchmark oficial do MBD. ([GitHub][5])

**Otimiza√ß√£o**

* **Valida√ß√£o:** GroupKFold por `client_id` **ou** usar o `fold` nativo do dataset; estratificar por alvo dentro das dobras, se poss√≠vel.
* **Estrat√©gia:** **Optuna** (Bayes/Tree-Parzen) com *early stopping* e **objetivo = AUPRC (valida√ß√£o)**.
* **Espa√ßos (exemplos):**

  * **LogReg:** C (1e-4‚Ä¶1e2), penalty (l1/l2), class\_weight (balanced/None).
  * **LightGBM:** num\_leaves, max\_depth, min\_data\_in\_leaf, feature\_fraction, bagging\_fraction, lambda\_l1/l2, learning\_rate.
  * **CatBoost:** depth, l2\_leaf\_reg, learning\_rate, border\_count; `scale_pos_weight`.
  * **ptls (seq):** hidden\_size, n\_layers, dropout, lr, seq\_len (subsequ√™ncias), embedding pooling.

**Compara√ß√£o**

* Treine todos os modelos nas mesmas dobras.
* Relate **AUPRC/ROC-AUC**, **Top-k** (5%, 10%, 20%), **calibra√ß√£o** e **curvas de ganho/lift**.
* Fa√ßa **abla√ß√£o por modalidade** (trx/geo/dialog) e **late-fusion** (concat/blending) ‚Äî tamb√©m alinhado ao reposit√≥rio dos autores. ([GitHub][5])
* Escolha o **melhor compromisso** entre **AUPRC**, **estabilidade nas dobras**, **custo/lat√™ncia** e **calibra√ß√£o**.

**Formula√ß√£o do problema**

Este estudo aborda a tarefa de **campanha (purchase prediction)**: dados hist√≥ricos multimodais de cada cliente at√© um m√™s de refer√™ncia `mon`, estima-se a **probabilidade de emiss√£o de produto no m√™s subsequente** (`target_1`). A formula√ß√£o segue o delineamento do **Multimodal Banking Dataset (MBD)**, que prov√™ r√≥tulos mensais (`target_1`‚Ä¶`target_4`) e dados temporais de **transa√ß√µes (trx)**, **atividade geogr√°fica (geo)** e **embeddings de di√°logos (dialog)**. (MOLLAEV et al., 2025). ([arXiv][1])

**Organiza√ß√£o dos dados**

O @tbl-mbd-schema apresenta a organiza√ß√£o do **MBD** realizada por @mollaev2025:

: Organiza√ß√£o dos dados do MBD (resumo) {#tbl-mbd-schema}

| Camada/Tabela | Campo (tipo) | Descri√ß√£o |
|---|---|---|
| client_split      | client_id (str); fold (int)              | ID anonimizado e dobra oficial                                | Split reprodut√≠vel; valida√ß√£o por cliente (evita vazamento)           |
| detail.dialog     | client_id; event_time; embedding (float[])| Intera√ß√µes de suporte como vetores (tempo + sem√¢ntica)        | Sinal de inten√ß√£o; agrega√ß√µes temporais; entrada para modelos         |
| detail.geo        | client_id; event_time; geohash_4/5/6     | Eventos espaciais hier√°rquicos no tempo                       | Mobilidade/mudan√ßa de rotina; resolu√ß√£o multi-escala                   |
| detail.trx        | client_id; event_time; amount; tipos...  | Transa√ß√µes com valores e c√≥digos de tipo/origem/destino       | N√∫cleo preditivo (RFM, mix, entropia, sazonalidade, co-ocorr√™ncias)   |
| ptls.*            | arrays por campo (por cliente)           | Sequ√™ncias agregadas por cliente (formato pytorch-lifestream) | Treino sequencial/auto-supervisionado sem *joins*                      |
| targets           | mon; target_1..4; trans_count; diff_trans_date; client_id; fold | R√≥tulos por m√™s e estat√≠sticas de rec√™ncia/volume | Define tarefa multirr√≥tulo; facilita baselines e an√°lise               |

Fonte: Adaptado de MOLLAEV, D. et al. (2025). DOI: 10.48550/arXiv.2409.17587. Tradu√ß√£o nossa.

Veja o [Ap√™ndice A ‚Äî Dicion√°rio de dados](#apx-dados).

**Dados, vers√µes e parti√ß√µes**

Utiliza-se o **MBD** hospedado na Hugging Face, com dados anonimizados por cliente ao longo de \~12 meses, concebido para prever propens√£o de compra ap√≥s a data de refer√™ncia. Para prototipagem e *tuning* inicial, emprega-se o **MBD-mini**, que preserva a estrutura e acelera ciclos de experimento, com posterior migra√ß√£o ao conjunto completo. Para reprodutibilidade, o carregamento √© fixado (*pinado*) a uma revis√£o espec√≠fica do dataset. (AI-LAB, 2025; MOLLAEV et al., 2025). ([Hugging Face][2], [arXiv][1])
A valida√ß√£o respeita a unidade natural de generaliza√ß√£o (**cliente**). Adota-se **GroupKFold** com **`client_id`** como agrupador ou, alternativamente, as **dobras (`fold`)** fornecidas pelo pr√≥prio dataset, evitando vazamento por sobreposi√ß√£o de clientes entre treino e valida√ß√£o. Em todas as montagens por m√™s de refer√™ncia, **somente eventos com `event_time` ‚â§ fim de `mon`** s√£o eleg√≠veis para *features* (‚Äúno-lookahead‚Äù). (MOLLAEV et al., 2025). ([arXiv][1])

**Pr√©-processamento e engenharia de atributos**

### Transa√ß√µes (trx)

Para cada par (`client_id`, `mon`), agregam-se janelas **1, 3 e 6 meses** at√© o fim de `mon`: (i) **volume/frequ√™ncia**: contagem de transa√ß√µes; rec√™ncia (dias desde a √∫ltima); (ii) **valor**: soma, mediana, desvio-padr√£o e ticket m√©dio de `amount`; (iii) **mix de tipos**: contagens/percentuais por `event_type` e `event_subtype`; (iv) **diversidade/rede**: n√∫mero de contrapartes √∫nicas e entropias em `dst_type*`/`src_type*`; (v) **sazonalidade**: indicadores de dia da semana/hora (one-hot e codifica√ß√£o seno/cosseno). (MOLLAEV et al., 2025). ([arXiv][1])

### Geolocaliza√ß√£o (geo)

A partir da sequ√™ncia de geohashes: (i) **intensidade/diversidade**: n√∫mero de eventos; c√©lulas √∫nicas em `geohash_5/6`; entropia espacial; (ii) **mobilidade**: *radius of gyration* aproximado, trocas de c√©lula, raz√µes dia/noite e semana/fim-de-semana; (iii) **rec√™ncia**: dias desde o √∫ltimo evento geo. (MOLLAEV et al., 2025). ([arXiv][1])

### Di√°logos (dialog)

Os **embeddings** de di√°logo s√£o agregados temporalmente por cliente via **m√©dia**, **m√°ximo**, **m√©dia ponderada pela rec√™ncia** e **vetor do √∫ltimo di√°logo**; aplica-se **PCA (16‚Äì64 dimens√µes)** sobre vetores agregados para reduzir dimensionalidade e mitigar *overfitting*. (MOLLAEV et al., 2025). ([arXiv][1])

### Jun√ß√£o e alvo

As *features* de cada modalidade s√£o unidas por (`client_id`, `mon`) e associadas ao r√≥tulo **bin√°rio** `target_1`. **Valores ausentes** p√≥s-agrega√ß√£o s√£o imputados com zero (ou estat√≠sticas de janela, quando aplic√°vel). Para experimentos com foco em tempo de execu√ß√£o, pode-se filtrar `is_balanced == 1`, preservando a compara√ß√£o final no conjunto completo. (AI-LAB, 2025). ([Hugging Face][2])

## Modelagem

### Trilho tabular (baseline de baixo custo)

Modelos sobre *features* agregadas: **Regress√£o Log√≠stica** (penaliza√ß√µes L1/L2 e `class_weight`), **Gradient Boosting** (LightGBM/XGBoost) e **CatBoost**. Este trilho oferece treinamento r√°pido, interpretabilidade (import√¢ncias/SHAP) e **baixa lat√™ncia de infer√™ncia** para uso em campanhas.

### Trilho sequencial (aprendizado de representa√ß√µes)

Explora-se o car√°ter **sequencial** por meio do ecossistema **pytorch-lifestream (ptls)**, que aprende **embeddings auto-supervisionados** de sequ√™ncias discretas em grande escala (por exemplo, **CoLES**). Treinam-se *encoders* para **trx** e/ou **geo** e, em seguida, aplica-se um **cabe√ßote leve** (MLP ou GBM) para prever `target_1`. (SBERBANK AI LAB, 2025; BABAEV et al., 2020). ([GitHub][3], [arXiv][4])

## Valida√ß√£o, ajuste de hiperpar√¢metros e m√©trica-alvo

O protocolo de valida√ß√£o usa **GroupKFold (5 dobras)** por **`client_id`** (ou *folds* nativos do MBD). A **m√©trica-alvo** de *tuning* √© **AUPRC (PR-AUC)**, apropriada a cen√°rios desbalanceados; **ROC-AUC** √© m√©trica complementar. O ajuste utiliza **Optuna** (Tree-Parzen) com *early stopping* quando suportado:
a) **LR**: `C` (log-space), `penalty` (L1/L2), `class_weight`;
b) **LightGBM**: `num_leaves`, `max_depth`, `min_data_in_leaf`, `feature_fraction`, `bagging_fraction`, `lambda_l1/l2`, `learning_rate`, `n_estimators`;
c) **CatBoost**: `depth`, `l2_leaf_reg`, `learning_rate`, `iterations`, `scale_pos_weight`;
d) **ptls**: `hidden_size`, `n_layers`, `dropout`, `lr`, `seq_len` e estrat√©gia de *pooling* dos *embeddings*. (SBERBANK AI LAB, 2025). ([GitHub][3])

**Abla√ß√£o, fus√£o e sele√ß√£o de limiar

Conduz-se **abla√ß√£o por modalidade** (somente trx; somente geo; somente dialog; multimodal) e **fus√£o tardia** por concatena√ß√£o de *features* ou *blending* de escores. A sele√ß√£o de limiar (œÑ) √© orientada por **calibra√ß√£o** (Brier/curva de confiabilidade) e **restri√ß√µes de or√ßamento** (p. ex., *precision\@k* no topo de 5‚Äì10% dos clientes). (MOLLAEV et al., 2025). ([arXiv][1])

**Controles de risco e vieses

Mitigam-se riscos com: (i) **bloqueio temporal** nas agrega√ß√µes (`event_time ‚â§ mon`); (ii) tratamento do **desbalanceamento** com AUPRC, `class_weight/scale_pos_weight` e avalia√ß√£o em **top-k**; (iii) **monitoramento de *drift*** (distribui√ß√µes de *features* e fra√ß√£o de positivos); (iv) an√°lise por **segmentos** para identificar vieses e impactos desiguais. (MOLLAEV et al., 2025). ([arXiv][1])

**Reprodutibilidade e implanta√ß√£o

Para reprodutibilidade, fixam-se **sementes**, **versionamento** de c√≥digo/artefatos, **pin** da revis√£o do dataset e registro de ambiente (vers√µes). Para implanta√ß√£o, *features* agregadas permitem *scoring* **batch** mensal com baixa lat√™ncia; no trilho sequencial, **embeddings ptls** podem ser pr√©-computados e servidos a um **classificador leve** (GBM/MLP), equilibrando desempenho e custo operacional. (AI-LAB, 2025; SBERBANK AI LAB, 2025). ([Hugging Face][2], [GitHub][3])

# Resultados

**C√≥digo base (funciona com MBD-mini para iterar r√°pido)**

> Use **MBD-mini** (‚âà10% dos clientes, mesma estrutura) para prototipar e depois migre ao completo. ([Hugging Face][8])

**1) Carregar dados e preparar snapshots**

```python
from datasets import load_dataset
import pandas as pd
import numpy as np

ds = load_dataset("ai-lab/MBD-mini")  # depois: "ai-lab/MBD"
# Tabelas: ds['client_split'], ds['detail.trx'], ds['detail.geo'], ds['detail.dialog'], ds['targets']

client_split = pd.DataFrame(ds['client_split'])
targets = pd.DataFrame(ds['targets'])

# Exemplo: manter apenas amostra balanceada para POC
clients_ok = client_split.query("is_balanced == 1")[["client_id","fold"]]

targets = targets.merge(clients_ok, on="client_id", how="inner")
```

**2) Agregar TRX at√© o m√™s de refer√™ncia**

```python
trx = pd.DataFrame(ds['detail.trx'])
trx = trx.merge(clients_ok, on="client_id")  # traz fold
trx["event_time"] = pd.to_datetime(trx["event_time"])

def make_trx_agg(df, until_month):
    m_end = pd.to_datetime(until_month) + pd.offsets.MonthEnd(0)
    dfm = df[df["event_time"] <= m_end]
    g = dfm.groupby("client_id")
    out = pd.DataFrame({
        "client_id": g.size().index,
        "trx_cnt_1m": g.size().values,
        "amt_sum": g["amount"].sum().values,
        "amt_med": g["amount"].median().values,
        "amt_std": g["amount"].std().fillna(0).values,
        "days_since_last_trx": (m_end - g["event_time"].max()).dt.days.values
    })
    return out

# Exemplo para um m√™s (fa√ßa loop por mon em targets)
mon = targets["mon"].iloc[0]
trx_agg = make_trx_agg(trx, mon)
```

**3) Features de GEO e DIALOG (sketch similar)**

```python
geo = pd.DataFrame(ds['detail.geo'])
geo["event_time"] = pd.to_datetime(geo["event_time"])
def make_geo_agg(df, until_month):
    m_end = pd.to_datetime(until_month) + pd.offsets.MonthEnd(0)
    dfx = df[df["event_time"] <= m_end]
    g = dfx.groupby("client_id")
    return pd.DataFrame({
        "client_id": g.size().index,
        "geo_events": g.size().values,
        "geo_cells6_unique": g["geohash_6"].nunique().values
    })
geo_agg = make_geo_agg(geo, mon)

dlg = pd.DataFrame(ds['detail.dialog'])
dlg["event_time"] = pd.to_datetime(dlg["event_time"])
# Cada linha tem um vetor "embedding" ‚Üí fa√ßa um pooling simples (mean) por cliente
def mean_pool(vecs):
    return np.mean(np.vstack(vecs), axis=0)

emb_dim = len(dlg["embedding"].iloc[0])
pool = dlg[dlg["event_time"] <= pd.to_datetime(mon) + pd.offsets.MonthEnd(0)] \
        .groupby("client_id")["embedding"].apply(mean_pool).reset_index()
emb_cols = [f"dlg_mean_{i}" for i in range(emb_dim)]
dlg_agg = pd.DataFrame(pool["embedding"].to_list(), columns=emb_cols)
dlg_agg.insert(0, "client_id", pool["client_id"])
```

**4) Montar dataset final + alvo e split por fold**

```python
X = targets.query("mon == @mon")[["client_id","target_1","fold"]] \
    .merge(trx_agg, on="client_id", how="left") \
    .merge(geo_agg, on="client_id", how="left") \
    .merge(dlg_agg, on="client_id", how="left") \
    .fillna(0)

y = X.pop("target_1").astype(int)
fold = X.pop("fold")
client_ids = X.pop("client_id")
```

**5) Treinar 3 estimadores + HPO (ex.: Optuna + GroupKFold)**

```python
import optuna
from sklearn.model_selection import GroupKFold
from sklearn.metrics import average_precision_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

def cv_ap(X, y, groups, clf):
    gkf = GroupKFold(n_splits=5)
    scores=[]
    for tr, va in gkf.split(X, y, groups):
        clf_ = clf
        clf_.fit(X.iloc[tr], y.iloc[tr])
        p = clf_.predict_proba(X.iloc[va])[:,1]
        scores.append(average_precision_score(y.iloc[va], p))
    return float(np.mean(scores))

# Baselines r√°pidos
ap_lr  = cv_ap(X, y, client_ids, LogisticRegression(max_iter=200, class_weight="balanced"))
ap_lgb = cv_ap(X, y, client_ids, LGBMClassifier(n_estimators=400, learning_rate=0.05))
ap_cat = cv_ap(X, y, client_ids, CatBoostClassifier(iterations=400, learning_rate=0.05, verbose=0))
print(ap_lr, ap_lgb, ap_cat)
```

> Para **sequencial/ptls**, use o formato `ptls.*` e treine um encoder (p.ex., **CoLES**) para `trx` e/ou `geo`, salve os **embeddings por cliente** e **alimente um GBM/MLP** ‚Äî exatamente como no benchmark (h√° scripts/notebooks oficiais). ([GitHub][5])

---

# Conclus√µes
## Perguntas-chave

**i. Resolve o problema?**
Se o **AUPRC** do melhor modelo superar com folga baselines simples (ex.: RegLog e rules-based) e entregar **lift** alto no top-k, sim ‚Äî o MBD foi criado justamente para **predi√ß√£o de compra futura (campaigning)** e mostrou vantagem do multimodal sobre unimodal. ([arXiv][1], [ar5iv][6])

**ii. Vai para produ√ß√£o? (checklist)**

(dados, lat√™ncia, monitoramento, √©tica/LGPD)

* **Dados online:** consegue materializar as features (ou sequ√™ncias) **diariamente/mensalmente** sem usar informa√ß√£o futura?
* **Latency/custo:** Tabular (LightGBM/CatBoost) √© leve; sequencial (ptls) pede GPU em treino, mas **inferencia** pode ser s√≥ MLP/GBM sobre embeddings pr√©-computados. Reposit√≥rio traz requisitos de HW/stack para o benchmark. ([GitHub][5])
* **Calibra√ß√£o & Or√ßamento:** defina um **threshold** para respeitar o budget (ex.: disparar para top 8% com prob ‚â• œÑ calibrado).
* **Monitoramento:** AUPRC em amostras de controle, **drift** de features, **fra√ß√£o de positivos** por segmento, e re-treino mensal/trimestral.
* **√âtica & privacidade:** MBD √© **anonimizado**; ainda assim avalie bias por **segmentos de cliente** (porte/regi√£o/setor). ([arXiv][7])

## Trabalhos futuros

* **Vazamento temporal** ao agregar al√©m de `mon`.
* **Desbalanceamento**: preferir **AUPRC**, `class_weight`/`scale_pos_weight` e **Top-k**.
* **Lat√™ncia & custo** para sequencial: usar embeddings pr√©-computados + GBM em produ√ß√£o. ([GitHub][5])

- **Download e convers√£o:**
  - Utiliza√ß√£o do script `baixa_arquivos_login.py` para baixar arquivos.
  - Convers√£o de arquivos `.xls`, `.xlsx`, `.xlsm` para SQLite.
- **Valida√ß√£o e Limpeza:**
  - Identifica√ß√£o de arquivos corrompidos e protegidos por senha.
- **Classifica√ß√£o das Devolu√ß√µes:**
  - Categorias definidas a partir das n√£o conformidades nos checklists.

* AI-LAB. **MBD ‚Äì Multimodal Banking Dataset**. Dataset. Hugging Face, 2025. Dispon√≠vel em: `https://huggingface.co/datasets/ai-lab/MBD`. Acesso em: 16 ago. 2025. ([Hugging Face][2])
* AI-LAB. **MBD-mini ‚Äì Multimodal Banking Dataset (vers√£o reduzida)**. Dataset. Hugging Face, 2025. Dispon√≠vel em: `https://huggingface.co/datasets/ai-lab/MBD-mini`. Acesso em: 16 ago. 2025. ([Hugging Face][5])
* BABAEV, D. **et al.** **CoLES: Contrastive Learning for Event Sequences with Self-Supervision**. *arXiv preprint* arXiv:2002.08232, 2020. Dispon√≠vel em: `https://arxiv.org/abs/2002.08232`. Acesso em: 16 ago. 2025. ([arXiv][4])
* MOLLAEV, D. **et al.** **Multimodal Banking Dataset: Understanding Client Needs through Event Sequences**. *arXiv preprint* arXiv:2409.17587, v2, 2025. DOI: 10.48550/arXiv.2409.17587. Dispon√≠vel em: `https://arxiv.org/abs/2409.17587`. Acesso em: 16 ago. 2025. ([arXiv][1])
* SBERBANK AI LAB. **pytorch-lifestream: a library for embeddings on discrete event sequences**. Software. GitHub, 2025. Dispon√≠vel em: `https://github.com/sberbank-ai-lab/pytorch-lifestream`. Acesso em: 16 ago. 2025. ([GitHub][3])

[1]: https://arxiv.org/pdf/2409.17587?utm_source=chatgpt.com "multimodal banking dataset: understanding client needs ..."
[2]: https://huggingface.co/datasets/ai-lab/MBD?utm_source=chatgpt.com "ai-lab/MBD ¬∑ Datasets at Hugging Face"
[3]: https://github.com/sberbank-ai-lab/pytorch-lifestream?utm_source=chatgpt.com "sberbank-ai-lab/pytorch-lifestream: A library built upon ..."
[4]: https://arxiv.org/abs/2002.08232?utm_source=chatgpt.com "CoLES: Contrastive Learning for Event Sequences with Self-Supervision"
[5]: https://huggingface.co/datasets/ai-lab/MBD-mini?utm_source=chatgpt.com "ai-lab/MBD-mini ¬∑ Datasets at Hugging Face"

* **Paper MBD (arXiv)** ‚Äì define tarefas **campaigning** e **matching** e descreve as modalidades/escala. ([arXiv][1])
* **Hugging Face ‚Äì MBD e MBD-mini** ‚Äì descri√ß√£o, estrutura, flag `is_balanced`, uso para prototipagem. ([Hugging Face][2])
* **pytorch-lifestream (ptls)** ‚Äì biblioteca para sequ√™ncias de eventos em larga escala. ([GitHub][4])
* **Repo do benchmark (GitHub)** ‚Äì notebooks, scripts, late-fusion, requisitos. ([GitHub][5])

[1]: https://arxiv.org/abs/2409.17587?utm_source=chatgpt.com "Multimodal Banking Dataset: Understanding Client Needs through Event Sequences"
[2]: https://huggingface.co/datasets/ai-lab/MBD?utm_source=chatgpt.com "ai-lab/MBD ¬∑ Datasets at Hugging Face"
[3]: https://arxiv.org/html/2409.17587v2?utm_source=chatgpt.com "Multimodal Banking Dataset: Understanding Client Needs ..."
[4]: https://github.com/dllllb/pytorch-lifestream?utm_source=chatgpt.com "pytorch-lifestream/pytorch-lifestream: A library built upon ..."
[5]: https://github.com/dzhambo/mbd "GitHub - Dzhambo/MBD"
[6]: https://ar5iv.labs.arxiv.org/html/2409.17587?utm_source=chatgpt.com "[2409.17587] Multimodal Banking Dataset ... - ar5iv - arXiv"
[7]: https://arxiv.org/pdf/2409.17587?utm_source=chatgpt.com "multimodal banking dataset: understanding client needs ..."
[8]: https://huggingface.co/datasets/ai-lab/MBD-mini?utm_source=chatgpt.com "ai-lab/MBD-mini ¬∑ Datasets at Hugging Face"

# Ap√™ndices {.unnumbered}
## Dicion√°rio de dados {.appendix .unnumbered #apx-dados}

**client_split**  
: `client_id` (str) ‚Äî identificador anonimizado do cliente.  
  `fold` (int) ‚Äî n√∫mero da dobra oficial do dataset.

**detail.dialog**  
: `client_id` (str); `event_time` (timestamp); `embedding` (float[]) ‚Äî vetor sem√¢ntico do di√°logo; `fold` (int).

**detail.geo**  
: `client_id` (str); `event_time` (timestamp); `fold` (int);  
  `geohash_4`/`geohash_5`/`geohash_6` (int) ‚Äî c√©lulas espaciais hier√°rquicas.

**detail.trx**  
: `client_id` (str); `event_time` (timestamp); `amount` (float); `fold` (int);  
  `event_type`, `event_subtype` (int) ‚Äî c√≥digos do tipo de transa√ß√£o;  
  `currency` (int) ‚Äî moeda codificada;  
  `src_type11`, `src_type12`, `src_type21`, `src_type22`, `src_type31`, `src_type32` (int) ‚Äî atributos do remetente;  
  `dst_type11`, `dst_type12` (int) ‚Äî atributos do destinat√°rio/contratante.

**ptls.dialog / ptls.geo / ptls.trx**  
: Mesmos campos, por√©m como **arrays** por cliente (sequ√™ncias temporais), no formato **pytorch-lifestream**.

**targets**  
: `mon` (str) ‚Äî m√™s de refer√™ncia;  
  `target_1`‚Ä¶`target_4` (int) ‚Äî emiss√£o nos meses +1‚Ä¶+4 (multirr√≥tulo);  
  `trans_count` (int) ‚Äî n¬∫ de transa√ß√µes no m√™s de refer√™ncia;  
  `diff_trans_date` (int) ‚Äî tempo entre transa√ß√µes;  
  `client_id` (str); `fold` (int).

*Fonte: Adaptado de MOLLAEV, D. et al. (2025). DOI: 10.48550/arXiv.2409.17587. Tradu√ß√£o nossa.*
