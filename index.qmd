---
title: "Projeto de Machine Learning I"
author: "Bruno Lenz, Danilo Santos, Diogo de Araujo, Jonathan e Osvaldo Jeronymo Neto"
date: today
date-format: long
lang: pt-BR
number-sections: true

format:
  html:
    toc: true
    theme: cosmo
    tbl-cap-location: top
---

# Introdução

Este projeto explora a aplicação de técnicas de *Machine Learning (ML)* para a análise de dados bancários **multimodais**, com o objetivo de desenvolver um modelo preditivo para otimizar campanhas de **cross-sell** (venda-cruzada). A análise se baseia no **Multimodal Banking Dataset (MBD)**, um conjunto de dados em larga escala que reflete interações reais de clientes corporativos.

O ciclo do projeto cobre: definição do problema de negócio; tratamento e transformação dos dados; escolha de métricas adequadas a **desbalanceamento** (AUPRC); desenvolvimento de pelo menos três estimadores; *tuning* de hiperparâmetros; comparação e seleção do melhor modelo; e registro reprodutível dos resultados.

# Contexto e problema de negócio

**Problema:** predição de propensão à compra em campanhas de *cross-sell*. Dado o histórico multimodal de cada cliente até um mês de referência `mon`, estimamos a probabilidade de **emissão de um produto no mês seguinte** (`target_1`).

**Por que AUPRC?** Em cenários de baixa prevalência de positivos, **PR-AUC (Average Precision)** é mais informativa que ROC-AUC. O *baseline* aleatório para AUPRC é aproximadamente a **prevalência** da classe positiva.

# Dados

Trabalhamos com o **MBD-mini** (≈10% dos clientes do MBD completo), que preserva a estrutura do conjunto principal e acelera a fase de prototipagem.

## Visão geral (resumo)

| Conjunto de dados | Nº de clientes | Tarefas | Nº de eventos | Balanço | Modalidades |
|---|---:|---|---:|---|---|
| MBD-mini | ~70 mil | Classificação binária multirrótulo; *matching* | ~80 milhões | Desbalanceado | Transações; Geo; Diálogos |
| MBD (completo) | ~2 milhões | Idem | ~2 bilhões | Altamente desbalanceado | Transações; Geo; Diálogos |

# Repositório (organização)

```
machine-learning-project/
├─ notebooks/
│  ├─ 01_explore_mbd_mini.ipynb    # EDA por objetivos (targets & client_split)
│  ├─ 02_features_tabular.ipynb    # Engenharia de atributos tabulares
│  ├─ 03_train_compare_tabular.ipynb  # Treino/validação e comparação
│  └─ 04_ptls_sequence_embeddings.ipynb # Sequências/embeddings (opcional)
├─ src/
│  └─ eda/
│     ├─ io_tar.py           # Leitura TAR + Parquet; reconstrói fold; normaliza mon
│     ├─ check_schema_vol.py # Esquema, vazamento, volumetria
│     ├─ prevalence.py       # Prevalência (ALL, por mês, por fold)
│     ├─ baseline.py         # Baseline AUPRC ≈ prevalência
│     └─ artifacts.py        # manifest.json (hashes, caminhos, notas)
├─ reports/                  # Artefatos gerados pela EDA (json/csv)
├─ requirements.txt          # pandas, pyarrow, etc.
└─ README.md
```

**Glossário rápido**  
- **fold**: partição para validação (GroupKFold por cliente). No *dataset*, o `fold` aparece no **caminho** dos arquivos parquet (`.../fold=K/part-*.parquet`) e é **reconstruído** na leitura.  
- **mon**: mês de referência; normalizado para `Period[M]` (ex.: `2022-09`).

# Notebook `01_explore_mbd_mini.ipynb` — passos

## 1) Leitura e normalização

- Abrir `targets.tar.gz` e `client_split.tar.gz`; varrer `part-*.parquet` sob `targets/` e `client_split/`.
- Extrair `fold` do caminho (`fold=K`) e inserir como coluna; converter `mon` para `Period[M]`.

## 2) Objetivo: Esquema & Volumetria

- **Esquema:** `dtypes`, nulos, `nunique`, memória, domínios (`target_* ∈ {0,1}`).  
- **Volumetria:** nº de linhas/clientes; distribuição por `mon` e por `fold`.  
- **Vazamento:** garantir que cada `client_id` apareça em **um único fold**.  
- **Saídas:** `reports/schema_*.json`, `reports/volumetria.json`, `reports/fold_leakage.csv` (se houver).

## 3) Objetivo: Prevalência por mês e por fold

- Tabela com linhas `ALL`, `mon=YYYY-MM`, `fold=K` × colunas `target_1..4`.  
- **Saída:** `reports/prevalencia.csv`.

## 4) Objetivo: Baseline AUPRC

- **AUPRC (aleatório) ≈ prevalência** → copiar a tabela de prevalência.  
- **Saída:** `reports/baseline_auprc.csv`.

## 5) Objetivo: Artefatos & Manifest

- **Manifesto:** `reports/manifest.json` com caminhos dos insumos, **hashes** (md5/sha256) dos `.tar.gz`, tamanhos e notas (dtype de `mon`, nº de linhas etc.).

# Resultados (exemplo de *run*)

Resumo típico impresso pelo notebook:

```
[INFO] Executando pipeline EDA...
[OK] Lidos 435 arquivos parquet de 'targets/' (fold recuperado)
[OK] Lidos 1000 arquivos parquet de 'client_split/' (fold recuperado)
[OK] volumetria.json salvo.
[OK] prevalencia.csv salvo.
[OK] baseline_auprc.csv salvo (≈ prevalência).
[OK] manifest.json salvo.

===== RESUMO =====
targets total rows: 1.202.688
nº de clientes (client_split): 100.224
```

> A linha `ALL` em `prevalencia.csv` é o **baseline** de AUPRC para cada `target_k`.

# Metodologia de modelagem (visão geral)

- **Features tabulares:** agregações de transações (RFM, sazonalidade, entropias), geo (diversidade/mobilidade) e diálogos (pooling de embeddings).  
- **Modelos:** Regressão Logística, LightGBM/XGBoost, CatBoost.  
- **Validação:** GroupKFold por `client_id` (ou `fold` nativo).  
- **Métrica-alvo:** **AUPRC**; complementares: ROC-AUC, Precision@k, Recall@k, Brier, calibração.  
- **HPO:** Optuna (TPE) com *early stopping* quando aplicável.

# Conclusões

- **Contratos de dados** (esquema/volumetria) e **integridade do split** (por cliente) são checados e registrados.  
- **Baseline honesto:** AUPRC ≈ prevalência → meta mínima para qualquer modelo.  
- **Reprodutibilidade:** artefatos versionados em `reports/` + `manifest.json` com hashes.

---

> Para detalhes operacionais da EDA (código e artefatos), veja o apêndice `apendice.qmd` neste mesmo projeto.
